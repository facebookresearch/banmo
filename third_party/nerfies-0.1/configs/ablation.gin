# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# This is a quarter HD configuration for 4 GPUs.
# The image scale is based on our input video size of 1920x1080.
# This configuration requires 4 GPUs to train.
#
# Note that this configuration has not been tested and may require further
# tuning.

num_warp_freqs = 8
elastic_init_weight = 0.01

# Predefined warp alpha schedules.
ANNEALED_WARP_ALPHA_SCHED = {
  'type': 'linear',
  'initial_value': 0.0,
  'final_value': %num_warp_freqs,
  'num_steps': 80000,
}
CONSTANT_WARP_ALPHA_SCHED = {
  'type': 'constant',
  'value': %num_warp_freqs,
}

# Predefined elastic loss schedules.
CONSTANT_ELASTIC_LOSS_SCHED = {
  'type': 'constant',
  'value': %elastic_init_weight,
}
DECAYING_ELASTIC_LOSS_SCHED = {
  'type': 'piecewise',
  'schedules': [
    (50000, ('constant', %elastic_init_weight)),
    (100000, ('cosine_easing', %elastic_init_weight, 1e-8, 100000)),
  ]
}

# Common configs.
ModelConfig.use_viewdirs = True
ModelConfig.use_stratified_sampling = True
ModelConfig.sigma_activation = @nn.softplus
ModelConfig.use_appearance_metadata = False

# Experiment configs.
ExperimentConfig.image_scale = %image_scale
ExperimentConfig.random_seed = 12345

# Warp field configs.
ModelConfig.use_warp = True
ModelConfig.warp_field_type = 'se3'
ModelConfig.num_warp_freqs = %num_warp_freqs
ModelConfig.num_warp_features = 8

# Use macros to make sure these are set somewhere.
TrainConfig.batch_size = %batch_size
TrainConfig.max_steps = %max_steps
TrainConfig.lr_schedule = {
  'type': 'exponential',
  'initial_value': %init_lr,
  'final_value': %final_lr,
  'num_steps': %lr_decay_steps,
}
TrainConfig.warp_alpha_schedule = %CONSTANT_WARP_ALPHA_SCHED

# Elastic loss.
TrainConfig.use_elastic_loss = True
TrainConfig.elastic_loss_weight_schedule = %DECAYING_ELASTIC_LOSS_SCHED

# Background regularization loss.
TrainConfig.use_background_loss = False
TrainConfig.background_loss_weight = 1.0

# Script interval configs.
TrainConfig.print_every = 100
TrainConfig.log_every = 500
TrainConfig.save_every = 5000

EvalConfig.eval_once = False
EvalConfig.save_output = True
EvalConfig.chunk = %eval_batch_size

ModelConfig.use_warp = True
ModelConfig.use_appearance_metadata = True

TrainConfig.warp_alpha_schedule = %ANNEALED_WARP_ALPHA_SCHED
TrainConfig.elastic_loss_weight_schedule = %DECAYING_ELASTIC_LOSS_SCHED
TrainConfig.use_elastic_loss = True
TrainConfig.use_background_loss = False

#max_steps = 500000 # 4gpu
#lr_decay_steps = 1000000 # 4gpu

max_steps = 250000
lr_decay_steps = 500000

image_scale = 4
#batch_size=1024 # 4gpu
#eval_batch_size=1024 # 4gpu
#batch_size = 3072
#eval_batch_size = 4096
#init_lr = 0.0007 # 4gpu
#final_lr = 0.00007

#batch_size=6144
batch_size=4096
eval_batch_size=8096 
init_lr = 0.001
final_lr = 0.0001

ModelConfig.num_nerf_point_freqs = 8
ModelConfig.nerf_trunk_width = 256
ModelConfig.nerf_trunk_depth = 8
ModelConfig.num_coarse_samples = 128
ModelConfig.num_fine_samples = 128

TrainConfig.print_every = 200
TrainConfig.log_every = 500
TrainConfig.save_every = 5000
