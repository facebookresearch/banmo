# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# This is the base configuration that is imported by other configurations.
# Do not run this configuration directly.

num_warp_freqs = 8
elastic_init_weight = 0.01

# Predefined warp alpha schedules.
ANNEALED_WARP_ALPHA_SCHED = {
  'type': 'linear',
  'initial_value': 0.0,
  'final_value': %num_warp_freqs,
  'num_steps': 80000,
}
CONSTANT_WARP_ALPHA_SCHED = {
  'type': 'constant',
  'value': %num_warp_freqs,
}

# Predefined elastic loss schedules.
CONSTANT_ELASTIC_LOSS_SCHED = {
  'type': 'constant',
  'value': %elastic_init_weight,
}
DECAYING_ELASTIC_LOSS_SCHED = {
  'type': 'piecewise',
  'schedules': [
    (50000, ('constant', %elastic_init_weight)),
    (100000, ('cosine_easing', %elastic_init_weight, 1e-8, 100000)),
  ]
}

# Common configs.
ModelConfig.use_viewdirs = True
ModelConfig.use_stratified_sampling = True
ModelConfig.sigma_activation = @nn.softplus
ModelConfig.use_appearance_metadata = False

# Experiment configs.
ExperimentConfig.image_scale = %image_scale
ExperimentConfig.random_seed = 12345

# Warp field configs.
ModelConfig.use_warp = True
ModelConfig.warp_field_type = 'se3'
ModelConfig.num_warp_freqs = %num_warp_freqs
ModelConfig.num_warp_features = 8

# Use macros to make sure these are set somewhere.
TrainConfig.batch_size = %batch_size
TrainConfig.max_steps = %max_steps
TrainConfig.lr_schedule = {
  'type': 'exponential',
  'initial_value': %init_lr,
  'final_value': %final_lr,
  'num_steps': %lr_decay_steps,
}
TrainConfig.warp_alpha_schedule = %CONSTANT_WARP_ALPHA_SCHED

# Elastic loss.
TrainConfig.use_elastic_loss = True
TrainConfig.elastic_loss_weight_schedule = %DECAYING_ELASTIC_LOSS_SCHED

# Background regularization loss.
TrainConfig.use_background_loss = False
TrainConfig.background_loss_weight = 1.0

# Script interval configs.
TrainConfig.print_every = 100
TrainConfig.log_every = 500
TrainConfig.save_every = 5000

EvalConfig.eval_once = False
EvalConfig.save_output = True
EvalConfig.chunk = %eval_batch_size
