{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMMWf9AQcdlp"
   },
   "source": [
    "# Render a Nerfie video!\n",
    "\n",
    "**Author**: [Keunhong Park](https://keunhong.com)\n",
    "\n",
    "[[Project Page](https://nerfies.github.io)]\n",
    "[[Paper](https://storage.googleapis.com/nerfies-public/videos/nerfies_paper.pdf)]\n",
    "[[Video](https://www.youtube.com/watch?v=MrKrnHhk8IA)]\n",
    "[[GitHub](https://github.com/google/nerfies)]\n",
    "\n",
    "This notebook renders a figure-8 orbit video using the test cameras generated in the capture processing notebook.\n",
    "\n",
    "You can also load your own custom cameras by modifying the code slightly.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Convert a video into our dataset format using the [capture processing notebook](https://colab.sandbox.google.com/github/google/nerfies/blob/main/notebooks/Nerfies_Capture_Processing.ipynb).\n",
    "2. Train a Nerfie model using the [training notebook](https://colab.sandbox.google.com/github/google/nerfies/blob/main/notebooks/Nerfies_Training.ipynb)\n",
    "3. Run this notebook!\n",
    "\n",
    "\n",
    "### Notes\n",
    " * Please report issues on the [GitHub issue tracker](https://github.com/google/nerfies/issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "YIDbV769cPn1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/gengshany/.conda/envs/nerfies/lib/python3.8/site-packages/jax/_src/config.py:163: UserWarning: enable_omnistaging() is a no-op in JAX versions 0.2.12 and higher;\n",
      "see https://github.com/google/jax/blob/main/design_notes/omnistaging.md\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @title Define imports and utility functions.\n",
    "\n",
    "import jax\n",
    "from jax.config import config as jax_config\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax import jax_utils\n",
    "from flax import optim\n",
    "from flax.metrics import tensorboard\n",
    "from flax.training import checkpoints\n",
    "jax_config.enable_omnistaging() # Linen requires enabling omnistaging\n",
    "\n",
    "from absl import logging\n",
    "from io import BytesIO\n",
    "import random as pyrandom\n",
    "import numpy as np\n",
    "import PIL\n",
    "import IPython\n",
    "import tempfile\n",
    "import imageio\n",
    "from IPython.display import display, HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "# Monkey patch logging.\n",
    "def myprint(msg, *args, **kwargs):\n",
    " print(msg % args)\n",
    "\n",
    "logging.info = myprint \n",
    "logging.warn = myprint\n",
    "logging.error = myprint\n",
    "\n",
    "\n",
    "def show_image(image, fmt='png'):\n",
    "    image = image_utils.image_to_uint8(image)\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(image).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "\n",
    "def show_video(frames, fps=30):\n",
    "  with tempfile.NamedTemporaryFile(suffix='.mp4') as f:\n",
    "    with imageio.get_writer(f.name, fps=fps) as writer:\n",
    "      for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "\n",
    "    with open(f.name,'rb') as f:\n",
    "      data_url = \"data:video/mp4;base64,\" + b64encode(f.read()).decode()\n",
    "    display(HTML(\"\"\"\n",
    "    <video controls autoplay loop>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\" % data_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/private/home/gengshany/code/vid2shape/third_party/nerfies-0.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "2QYJ7dyMcw2f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ./logs/T_swing1//config.gin\n",
      "Saving config to logs/T_swing1/config.gin\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Macros:\n",
       "\n",
       "    ANNEALED_WARP_ALPHA_SCHED = \\\n",
       "        {'final_value': %num_warp_freqs,\n",
       "         'initial_value': 0.0,\n",
       "         'num_steps': 80000,\n",
       "         'type': 'linear'}\n",
       "    batch_size = 4096\n",
       "    DECAYING_ELASTIC_LOSS_SCHED = \\\n",
       "        {'schedules': [(50000, ('constant', %elastic_init_weight)),\n",
       "                       (100000,\n",
       "                        ('cosine_easing', %elastic_init_weight, 1e-08, 100000))],\n",
       "         'type': 'piecewise'}\n",
       "    elastic_init_weight = 0.01\n",
       "    final_lr = 0.0001\n",
       "    image_scale = 4\n",
       "    init_lr = 0.001\n",
       "    lr_decay_steps = 500000\n",
       "    max_steps = 250000\n",
       "    num_warp_freqs = 8\n",
       "    \n",
       "#### Parameters for EvalConfig:\n",
       "\n",
       "    EvalConfig.chunk = 8192\n",
       "    EvalConfig.eval_once = False\n",
       "    EvalConfig.num_test_eval = 10\n",
       "    EvalConfig.num_train_eval = 10\n",
       "    EvalConfig.num_val_eval = None\n",
       "    EvalConfig.save_output = True\n",
       "    \n",
       "#### Parameters for ExperimentConfig:\n",
       "\n",
       "    ExperimentConfig.datasource_spec = None\n",
       "    ExperimentConfig.datasource_type = 'nerfies'\n",
       "    ExperimentConfig.image_scale = %image_scale\n",
       "    ExperimentConfig.random_seed = 12345\n",
       "    ExperimentConfig.subname = None\n",
       "    \n",
       "#### Parameters for ModelConfig:\n",
       "\n",
       "    ModelConfig.alpha_channels = 1\n",
       "    ModelConfig.appearance_metadata_dims = 8\n",
       "    ModelConfig.camera_metadata_dims = 2\n",
       "    ModelConfig.nerf_condition_depth = 1\n",
       "    ModelConfig.nerf_condition_width = 128\n",
       "    ModelConfig.nerf_skips = (4,)\n",
       "    ModelConfig.nerf_trunk_depth = 8\n",
       "    ModelConfig.nerf_trunk_width = 256\n",
       "    ModelConfig.noise_std = None\n",
       "    ModelConfig.num_coarse_samples = 128\n",
       "    ModelConfig.num_fine_samples = 128\n",
       "    ModelConfig.num_nerf_point_freqs = 8\n",
       "    ModelConfig.num_nerf_viewdir_freqs = 4\n",
       "    ModelConfig.num_warp_features = 8\n",
       "    ModelConfig.num_warp_freqs = %num_warp_freqs\n",
       "    ModelConfig.rgb_channels = 3\n",
       "    ModelConfig.sigma_activation = @nn.softplus\n",
       "    ModelConfig.use_appearance_metadata = True\n",
       "    ModelConfig.use_camera_metadata = False\n",
       "    ModelConfig.use_linear_disparity = False\n",
       "    ModelConfig.use_sample_at_infinity = True\n",
       "    ModelConfig.use_stratified_sampling = True\n",
       "    ModelConfig.use_viewdirs = True\n",
       "    ModelConfig.use_warp = True\n",
       "    ModelConfig.use_white_background = False\n",
       "    ModelConfig.warp_field_type = 'se3'\n",
       "    \n",
       "#### Parameters for TrainConfig:\n",
       "\n",
       "    TrainConfig.background_loss_weight = 1.0\n",
       "    TrainConfig.background_points_batch_size = 16384\n",
       "    TrainConfig.batch_size = %batch_size\n",
       "    TrainConfig.elastic_loss_weight_schedule = %DECAYING_ELASTIC_LOSS_SCHED\n",
       "    TrainConfig.elastic_reduce_method = 'weight'\n",
       "    TrainConfig.log_every = 500\n",
       "    TrainConfig.lr_schedule = \\\n",
       "        {'final_value': %final_lr,\n",
       "         'initial_value': %init_lr,\n",
       "         'num_steps': %lr_decay_steps,\n",
       "         'type': 'exponential'}\n",
       "    TrainConfig.max_steps = %max_steps\n",
       "    TrainConfig.print_every = 200\n",
       "    TrainConfig.save_every = 5000\n",
       "    TrainConfig.use_background_loss = False\n",
       "    TrainConfig.use_elastic_loss = True\n",
       "    TrainConfig.warp_alpha_schedule = %ANNEALED_WARP_ALPHA_SCHED"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Model and dataset configuration\n",
    "# @markdown Change the directories to where you saved your capture and experiment.\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/private/home/gengshany/code/vid2shape/third_party/nerfies-0.1/')\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import gin\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from nerfies import configs\n",
    "\n",
    "seqname='T_swing1'\n",
    "# @markdown The working directory where the trained model is.\n",
    "train_dir = './logs/%s/'%(seqname)  # @param {type: \"string\"}\n",
    "# @markdown The directory to the dataset capture.\n",
    "data_dir = 'dataset/%s/'%(seqname)  # @param {type: \"string\"}\n",
    "\n",
    "checkpoint_dir = Path(train_dir, 'checkpoints')\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "config_path = '%s/config.gin'%(train_dir)\n",
    "with open(config_path, 'r') as f:\n",
    "  logging.info('Loading config from %s', config_path)\n",
    "  config_str = f.read()\n",
    "gin.parse_config(config_str)\n",
    "\n",
    "config_path = Path(train_dir, 'config.gin')\n",
    "with open(config_path, 'w') as f:\n",
    "  logging.info('Saving config to %s', config_path)\n",
    "  f.write(config_str)\n",
    "\n",
    "exp_config = configs.ExperimentConfig()\n",
    "model_config = configs.ModelConfig()\n",
    "train_config = configs.TrainConfig()\n",
    "eval_config = configs.EvalConfig()\n",
    "\n",
    "display(Markdown(\n",
    "    gin.config.markdownify_operative_config_str(gin.operative_config_str())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6T7LQ5QSmu4o"
   },
   "outputs": [],
   "source": [
    "# @title Create datasource and show an example.\n",
    "\n",
    "from nerfies import datasets\n",
    "from nerfies import image_utils\n",
    "\n",
    "datasource_spec = exp_config.datasource_spec\n",
    "if datasource_spec is None:\n",
    "    datasource_spec = {\n",
    "        'type': exp_config.datasource_type,\n",
    "        'data_dir': data_dir,\n",
    "    }\n",
    "datasource = datasets.from_config(\n",
    "  datasource_spec,\n",
    "  image_scale=exp_config.image_scale,\n",
    "  #image_scale=1,\n",
    "  use_appearance_id=model_config.use_appearance_metadata,\n",
    "  use_camera_id=model_config.use_camera_metadata,\n",
    "  use_warp_id=model_config.use_warp,\n",
    "  random_seed=exp_config.random_seed)\n",
    "\n",
    "show_image(datasource.load_rgb(datasource.train_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jEO3xcxpnCqx"
   },
   "outputs": [],
   "source": [
    "# @title Initialize model\n",
    "# @markdown Defines the model and initializes its parameters.\n",
    "\n",
    "from flax.training import checkpoints\n",
    "from nerfies import models\n",
    "from nerfies import model_utils\n",
    "from nerfies import schedules\n",
    "from nerfies import training\n",
    "\n",
    "\n",
    "rng = random.PRNGKey(exp_config.random_seed)\n",
    "np.random.seed(exp_config.random_seed + jax.host_id())\n",
    "devices = jax.devices()\n",
    "\n",
    "learning_rate_sched = schedules.from_config(train_config.lr_schedule)\n",
    "warp_alpha_sched = schedules.from_config(train_config.warp_alpha_schedule)\n",
    "elastic_loss_weight_sched = schedules.from_config(\n",
    "    train_config.elastic_loss_weight_schedule)\n",
    "\n",
    "rng, key = random.split(rng)\n",
    "params = {}\n",
    "model, params['model'] = models.nerf(\n",
    "    key,\n",
    "    model_config,\n",
    "    batch_size=train_config.batch_size,\n",
    "    num_appearance_embeddings=len(datasource.appearance_ids),\n",
    "    num_camera_embeddings=len(datasource.camera_ids),\n",
    "    num_warp_embeddings=len(datasource.warp_ids),\n",
    "    near=datasource.near,\n",
    "    far=datasource.far,\n",
    "    use_warp_jacobian=train_config.use_elastic_loss,\n",
    "    use_weights=train_config.use_elastic_loss)\n",
    "\n",
    "optimizer_def = optim.Adam(learning_rate_sched(0))\n",
    "optimizer = optimizer_def.create(params)\n",
    "state = model_utils.TrainState(\n",
    "    optimizer=optimizer,\n",
    "    warp_alpha=warp_alpha_sched(0))\n",
    "scalar_params = training.ScalarParams(\n",
    "    learning_rate=learning_rate_sched(0),\n",
    "    elastic_loss_weight=elastic_loss_weight_sched(0),\n",
    "    background_loss_weight=train_config.background_loss_weight)\n",
    "logging.info('Restoring checkpoint from %s', checkpoint_dir)\n",
    "#state = checkpoints.restore_checkpoint(checkpoint_dir, state,step=1000)\n",
    "state = checkpoints.restore_checkpoint(checkpoint_dir, state)\n",
    "step = state.optimizer.state.step + 1\n",
    "state = jax_utils.replicate(state, devices=devices)\n",
    "del params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2KYhbpsklwAy"
   },
   "outputs": [],
   "source": [
    "# @title Define pmapped render function.\n",
    "\n",
    "import functools\n",
    "from nerfies import evaluation\n",
    "from importlib import reload  \n",
    "\n",
    "devices = jax.devices()\n",
    "\n",
    "\n",
    "def _model_fn(key_0, key_1, params, rays_dict, alpha):\n",
    "  out = model.apply({'params': params},\n",
    "                    rays_dict,\n",
    "                    warp_alpha=alpha,\n",
    "                    rngs={\n",
    "                        'coarse': key_0,\n",
    "                        'fine': key_1\n",
    "                    },\n",
    "                    mutable=False)\n",
    "  return jax.lax.all_gather(out, axis_name='batch')\n",
    "\n",
    "pmodel_fn = jax.pmap(\n",
    "    # Note rng_keys are useless in eval mode since there's no randomness.\n",
    "    _model_fn,\n",
    "    # key0, key1, params, rays_dict, alpha\n",
    "    in_axes=(0, 0, 0, 0, 0),\n",
    "    devices=devices,\n",
    "    donate_argnums=(3,),  # Donate the 'rays' argument.\n",
    "    axis_name='batch',\n",
    ")\n",
    "\n",
    "render_fn = functools.partial(evaluation.render_image,\n",
    "                              model_fn=pmodel_fn,\n",
    "                              device_count=len(devices),\n",
    "                              chunk=eval_config.chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73Fq0kNcmAra"
   },
   "outputs": [],
   "source": [
    "# @title Load cameras.\n",
    "\n",
    "from nerfies import utils\n",
    "\n",
    "\n",
    "test_camera_paths = datasource.glob_cameras(Path(data_dir, 'camera'))\n",
    "#test_camera_paths = datasource.glob_cameras('dataset/syn-eagled-/camera/')\n",
    "test_cameras = utils.parallel_map(datasource.load_camera, test_camera_paths, show_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "aP9LjiAZmoRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frame 1/150\n",
      "\tRendering ray batch: 0/1920000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/gengshany/.conda/envs/nerfies/lib/python3.8/site-packages/jax/lib/xla_bridge.py:382: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @title Render video frames.\n",
    "import ipyplot\n",
    "from nerfies import visualization as viz\n",
    "\n",
    "rng = rng + jax.host_id()  # Make random seed separate across hosts.\n",
    "keys = random.split(rng, len(devices))\n",
    "\n",
    "results = []\n",
    "for i in range(len(test_cameras)):\n",
    " # if i%10!=0 or i>100:continue\n",
    "  print(f'Rendering frame {i+1}/{len(test_cameras)}')\n",
    "  camera = test_cameras[i]\n",
    "  batch = datasets.camera_to_rays(camera)\n",
    "  batch['metadata'] = {\n",
    "      'appearance': i*jnp.ones_like(batch['origins'][..., 0, jnp.newaxis], jnp.uint32),\n",
    "      'warp': i*jnp.ones_like(batch['origins'][..., 0, jnp.newaxis], jnp.uint32),\n",
    "  }\n",
    "\n",
    "  pred_color, pred_depth, pred_depth_med, pred_acc = render_fn(state, batch, rng=rng)\n",
    "  results.append((pred_color, pred_depth, pred_acc))\n",
    "  pred_depth_viz = viz.colorize(pred_depth.squeeze(), cmin=datasource.near, cmax=datasource.far, invert=True)\n",
    "  ##break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3847017/3099232105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_depth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_depth' is not defined"
     ]
    }
   ],
   "source": [
    "show_image(np.array(pred_depth[:,:,0]))\n",
    "show_image(np.array(pred_color))\n",
    "show_image(np.array(pred_acc[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "_5hHR9XVm8Ix"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video controls autoplay loop>\n",
       "      <source src=\"data:video/mp4;base64,\" type=\"video/mp4\">\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Show rendered video.\n",
    "\n",
    "fps = 10  # @param {type:'number'}\n",
    "\n",
    "frames = []\n",
    "for rgb, depth,acc in results:\n",
    "  depth_viz = viz.colorize(depth.squeeze(), cmin=datasource.near, cmax=datasource.far, invert=True)\n",
    "  acc_viz = viz.colorize(acc.squeeze())\n",
    "\n",
    "  frame = np.concatenate([rgb, depth_viz], axis=1)\n",
    "\n",
    "  frames.append(image_utils.image_to_uint8(frame))\n",
    "\n",
    "show_video(frames, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/gengshany/.conda/envs/nerfies/lib/python3.8/site-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from jax import tree_util\n",
    "import time\n",
    "from importlib import reload  \n",
    "reload(models)\n",
    "\n",
    "model, _ = models.nerf_mesh(\n",
    "    key,\n",
    "    model_config,\n",
    "    batch_size=train_config.batch_size,\n",
    "    num_appearance_embeddings=len(datasource.appearance_ids),\n",
    "    num_camera_embeddings=len(datasource.camera_ids),\n",
    "    num_warp_embeddings=len(datasource.warp_ids),\n",
    "    near=datasource.near,\n",
    "    far=datasource.far,\n",
    "    use_warp_jacobian=train_config.use_elastic_loss,\n",
    "    use_weights=train_config.use_elastic_loss)\n",
    "\n",
    "def _model_fn(key_0, key_1, params, rays_dict, alpha):\n",
    "  out = model.apply({'params': params},\n",
    "                    rays_dict,\n",
    "                    warp_alpha=alpha,\n",
    "                    rngs={\n",
    "                        'coarse': key_0,\n",
    "                        'fine': key_1\n",
    "                    },\n",
    "                    mutable=False)\n",
    "  return jax.lax.all_gather(out, axis_name='batch')\n",
    "\n",
    "pmodel_fn = jax.pmap(\n",
    "    # Note rng_keys are useless in eval mode since there's no randomness.\n",
    "    _model_fn,\n",
    "    # key0, key1, params, rays_dict, alpha\n",
    "    in_axes=(0, 0, 0, 0, 0),\n",
    "    devices=devices,\n",
    "    donate_argnums=(3,),  # Donate the 'rays' argument.\n",
    "    axis_name='batch',\n",
    ")\n",
    "\n",
    "device_count=len(devices)\n",
    "chunk=eval_config.chunk\n",
    "model_fn = pmodel_fn\n",
    "\n",
    "\n",
    "_, key_0, key_1 = jax.random.split(rng, 3)\n",
    "key_0 = jax.random.split(key_0, device_count)\n",
    "key_1 = jax.random.split(key_1, device_count)\n",
    "host_id = jax.host_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mesh(bs_pts, chunk, rays_dict, device_count, key_0, key_1, state):\n",
    "    occ = []\n",
    "    for i in range(0, bs_pts, chunk):\n",
    "        #logging.info('\\tRendering ray batch: %d/%d', i, num_rays)\n",
    "        # pylint: disable=cell-var-from-loop\n",
    "        chunk_slice_fn = lambda x: x[i:i + chunk]\n",
    "        chunk_rays_dict = tree_util.tree_map(chunk_slice_fn, rays_dict)\n",
    "        num_chunk_rays = chunk_rays_dict['query_xyz'].shape[0]\n",
    "        remainder = num_chunk_rays % device_count\n",
    "        if remainder != 0:\n",
    "          padding = device_count - remainder\n",
    "          # pylint: disable=cell-var-from-loop\n",
    "          chunk_pad_fn = lambda x: jnp.pad(x, ((0, padding), (0, 0)), mode='edge')\n",
    "          chunk_rays_dict = tree_util.tree_map(chunk_pad_fn, chunk_rays_dict)\n",
    "        else:\n",
    "          padding = 0\n",
    "        # After padding the number of chunk_rays is always divisible by\n",
    "        # host_count.\n",
    "        per_host_rays = num_chunk_rays // jax.host_count()\n",
    "        chunk_rays_dict = tree_util.tree_map(\n",
    "            lambda x: x[(host_id * per_host_rays):((host_id + 1) * per_host_rays)],\n",
    "            chunk_rays_dict)\n",
    "        chunk_rays_dict = utils.shard(chunk_rays_dict, device_count)\n",
    "\n",
    "        model_out = model_fn(\n",
    "            key_0,\n",
    "            key_1,\n",
    "            state.optimizer.target['model'],\n",
    "            chunk_rays_dict,\n",
    "            state.warp_alpha)\n",
    "        occ.append(utils.unshard(model_out['alpha'][0], padding))\n",
    "    occ = jnp.concatenate(occ, axis=0)\n",
    "\n",
    "    vol_o = np.asarray(occ.reshape((grid_size, grid_size, grid_size)))\n",
    "    return vol_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import mcubes\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "outseqname = 'nerfies_%s'%(seqname)\n",
    "target_dir='/private/home/gengshany/code/vid2shape/logdir/baseline-%s/'%outseqname\n",
    "! rm -rf \"$target_dir\"\n",
    "os.mkdir(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "fraction occupied: 0.037905216217041016\n",
      "1\n",
      "fraction occupied: 0.037088871002197266\n",
      "2\n",
      "fraction occupied: 0.037450313568115234\n",
      "3\n",
      "fraction occupied: 0.037206172943115234\n",
      "4\n",
      "fraction occupied: 0.037044525146484375\n",
      "5\n",
      "fraction occupied: 0.03691577911376953\n",
      "6\n",
      "fraction occupied: 0.03638124465942383\n",
      "7\n",
      "fraction occupied: 0.037068843841552734\n",
      "8\n",
      "fraction occupied: 0.036667823791503906\n",
      "9\n",
      "fraction occupied: 0.03598356246948242\n",
      "10\n",
      "fraction occupied: 0.035329341888427734\n",
      "11\n",
      "fraction occupied: 0.03521299362182617\n",
      "12\n",
      "fraction occupied: 0.035405635833740234\n",
      "13\n",
      "fraction occupied: 0.03443193435668945\n",
      "14\n",
      "fraction occupied: 0.03364992141723633\n",
      "15\n",
      "fraction occupied: 0.03340578079223633\n",
      "16\n",
      "fraction occupied: 0.033252716064453125\n",
      "17\n",
      "fraction occupied: 0.0329594612121582\n",
      "18\n",
      "fraction occupied: 0.032441139221191406\n",
      "19\n",
      "fraction occupied: 0.0320286750793457\n",
      "20\n",
      "fraction occupied: 0.0320734977722168\n",
      "21\n",
      "fraction occupied: 0.031513214111328125\n",
      "22\n",
      "fraction occupied: 0.030391216278076172\n",
      "23\n",
      "fraction occupied: 0.030228614807128906\n",
      "24\n",
      "fraction occupied: 0.029564857482910156\n",
      "25\n",
      "fraction occupied: 0.02998495101928711\n",
      "26\n",
      "fraction occupied: 0.02917003631591797\n",
      "27\n",
      "fraction occupied: 0.029106616973876953\n",
      "28\n",
      "fraction occupied: 0.028627872467041016\n",
      "29\n",
      "fraction occupied: 0.028234481811523438\n",
      "30\n",
      "fraction occupied: 0.02811431884765625\n",
      "31\n",
      "fraction occupied: 0.02846527099609375\n",
      "32\n",
      "fraction occupied: 0.028968334197998047\n",
      "33\n",
      "fraction occupied: 0.029648780822753906\n",
      "34\n",
      "fraction occupied: 0.030353069305419922\n",
      "35\n",
      "fraction occupied: 0.031290531158447266\n",
      "36\n",
      "fraction occupied: 0.03178215026855469\n",
      "37\n",
      "fraction occupied: 0.031903743743896484\n",
      "38\n",
      "fraction occupied: 0.03164100646972656\n",
      "39\n",
      "fraction occupied: 0.03169965744018555\n",
      "40\n",
      "fraction occupied: 0.03133726119995117\n",
      "41\n",
      "fraction occupied: 0.03236103057861328\n",
      "42\n",
      "fraction occupied: 0.03410911560058594\n",
      "43\n",
      "fraction occupied: 0.035213470458984375\n",
      "44\n",
      "fraction occupied: 0.03633689880371094\n",
      "45\n",
      "fraction occupied: 0.03887033462524414\n",
      "46\n",
      "fraction occupied: 0.040067195892333984\n",
      "47\n",
      "fraction occupied: 0.0429530143737793\n",
      "48\n",
      "fraction occupied: 0.04472970962524414\n",
      "49\n",
      "fraction occupied: 0.04523515701293945\n",
      "50\n",
      "fraction occupied: 0.048374176025390625\n",
      "51\n",
      "fraction occupied: 0.04910564422607422\n",
      "52\n",
      "fraction occupied: 0.049355506896972656\n",
      "53\n",
      "fraction occupied: 0.04939603805541992\n",
      "54\n",
      "fraction occupied: 0.048169612884521484\n",
      "54\n",
      "fraction occupied: 0.048169612884521484\n",
      "56\n",
      "fraction occupied: 0.04750823974609375\n",
      "57\n",
      "fraction occupied: 0.04896974563598633\n",
      "58\n",
      "fraction occupied: 0.04867839813232422\n",
      "59\n",
      "fraction occupied: 0.04903411865234375\n",
      "60\n",
      "fraction occupied: 0.048839569091796875\n",
      "61\n",
      "fraction occupied: 0.04936695098876953\n",
      "62\n",
      "fraction occupied: 0.049022674560546875\n",
      "63\n",
      "fraction occupied: 0.04883289337158203\n",
      "64\n",
      "fraction occupied: 0.04892253875732422\n",
      "65\n",
      "fraction occupied: 0.048996925354003906\n",
      "66\n",
      "fraction occupied: 0.04898500442504883\n",
      "67\n",
      "fraction occupied: 0.04932832717895508\n",
      "68\n",
      "fraction occupied: 0.0493464469909668\n",
      "69\n",
      "fraction occupied: 0.0497736930847168\n",
      "70\n",
      "fraction occupied: 0.05000638961791992\n",
      "71\n",
      "fraction occupied: 0.050127506256103516\n",
      "72\n",
      "fraction occupied: 0.051540374755859375\n",
      "73\n",
      "fraction occupied: 0.051323890686035156\n",
      "74\n",
      "fraction occupied: 0.051349639892578125\n",
      "75\n",
      "fraction occupied: 0.051568031311035156\n",
      "76\n",
      "fraction occupied: 0.0524907112121582\n",
      "77\n",
      "fraction occupied: 0.052051544189453125\n",
      "78\n",
      "fraction occupied: 0.05306386947631836\n",
      "78\n",
      "fraction occupied: 0.05306386947631836\n",
      "80\n",
      "fraction occupied: 0.05290365219116211\n",
      "81\n",
      "fraction occupied: 0.053071022033691406\n",
      "82\n",
      "fraction occupied: 0.05327892303466797\n",
      "83\n",
      "fraction occupied: 0.053386688232421875\n",
      "84\n",
      "fraction occupied: 0.05311250686645508\n",
      "85\n",
      "fraction occupied: 0.05340385437011719\n",
      "86\n",
      "fraction occupied: 0.05353546142578125\n",
      "87\n",
      "fraction occupied: 0.053002357482910156\n",
      "88\n",
      "fraction occupied: 0.0533299446105957\n",
      "89\n",
      "fraction occupied: 0.05305290222167969\n",
      "90\n",
      "fraction occupied: 0.053217411041259766\n",
      "91\n",
      "fraction occupied: 0.05192375183105469\n",
      "92\n",
      "fraction occupied: 0.05168581008911133\n",
      "93\n",
      "fraction occupied: 0.05220746994018555\n",
      "94\n",
      "fraction occupied: 0.05182933807373047\n",
      "95\n",
      "fraction occupied: 0.05137968063354492\n",
      "96\n",
      "fraction occupied: 0.05106496810913086\n",
      "96\n",
      "fraction occupied: 0.05106496810913086\n",
      "98\n",
      "fraction occupied: 0.05025148391723633\n",
      "99\n",
      "fraction occupied: 0.049321651458740234\n",
      "100\n",
      "fraction occupied: 0.048534393310546875\n",
      "101\n",
      "fraction occupied: 0.047756195068359375\n",
      "102\n",
      "fraction occupied: 0.04583930969238281\n",
      "103\n",
      "fraction occupied: 0.04299783706665039\n",
      "104\n",
      "fraction occupied: 0.0409703254699707\n",
      "105\n",
      "fraction occupied: 0.038691043853759766\n",
      "106\n",
      "fraction occupied: 0.03749704360961914\n",
      "107\n",
      "fraction occupied: 0.03514862060546875\n",
      "108\n",
      "fraction occupied: 0.03436756134033203\n",
      "109\n",
      "fraction occupied: 0.032732486724853516\n",
      "109\n",
      "fraction occupied: 0.032732486724853516\n",
      "111\n",
      "fraction occupied: 0.03125429153442383\n",
      "112\n",
      "fraction occupied: 0.030238628387451172\n",
      "113\n",
      "fraction occupied: 0.03025960922241211\n",
      "114\n",
      "fraction occupied: 0.0303192138671875\n",
      "115\n",
      "fraction occupied: 0.03150510787963867\n",
      "116\n",
      "fraction occupied: 0.032891273498535156\n",
      "117\n",
      "fraction occupied: 0.03183555603027344\n",
      "118\n",
      "fraction occupied: 0.030603408813476562\n",
      "119\n",
      "fraction occupied: 0.031129837036132812\n",
      "120\n",
      "fraction occupied: 0.030800342559814453\n",
      "121\n",
      "fraction occupied: 0.031128883361816406\n",
      "122\n",
      "fraction occupied: 0.03187274932861328\n",
      "122\n",
      "fraction occupied: 0.03187274932861328\n",
      "124\n",
      "fraction occupied: 0.0334172248840332\n",
      "125\n",
      "fraction occupied: 0.035012245178222656\n",
      "126\n",
      "fraction occupied: 0.035643577575683594\n",
      "127\n",
      "fraction occupied: 0.03605985641479492\n",
      "128\n",
      "fraction occupied: 0.03769683837890625\n",
      "129\n",
      "fraction occupied: 0.03885173797607422\n",
      "130\n",
      "fraction occupied: 0.03885841369628906\n",
      "131\n",
      "fraction occupied: 0.0397486686706543\n",
      "132\n",
      "fraction occupied: 0.04055023193359375\n",
      "133\n",
      "fraction occupied: 0.04253673553466797\n",
      "134\n",
      "fraction occupied: 0.043155670166015625\n",
      "135\n",
      "fraction occupied: 0.043656349182128906\n",
      "136\n",
      "fraction occupied: 0.04443216323852539\n",
      "137\n",
      "fraction occupied: 0.04608774185180664\n",
      "138\n",
      "fraction occupied: 0.04670858383178711\n",
      "139\n",
      "fraction occupied: 0.04699516296386719\n",
      "140\n",
      "fraction occupied: 0.04712629318237305\n",
      "141\n",
      "fraction occupied: 0.0478367805480957\n",
      "142\n",
      "fraction occupied: 0.04844045639038086\n",
      "143\n",
      "fraction occupied: 0.04870319366455078\n",
      "144\n",
      "fraction occupied: 0.04887104034423828\n",
      "145\n",
      "fraction occupied: 0.04906463623046875\n",
      "146\n",
      "fraction occupied: 0.0493927001953125\n",
      "147\n",
      "fraction occupied: 0.049269676208496094\n",
      "148\n",
      "fraction occupied: 0.049910545349121094\n",
      "149\n",
      "fraction occupied: 0.049724578857421875\n"
     ]
    }
   ],
   "source": [
    "#bound=(datasource.far-datasource.near)/4\n",
    "bound=(datasource.far-datasource.near)/16\n",
    "#bound=(datasource.far-datasource.near)\n",
    "\n",
    "frame_len=len(test_cameras)\n",
    "#render_len=15\n",
    "render_len=frame_len\n",
    "grid_size = 128\n",
    "#grid_size = 12\n",
    "#threshold = 50\n",
    "threshold = 100\n",
    "\n",
    "pts = np.linspace(-bound, bound, grid_size).astype(np.float32)\n",
    "query_yxz = np.stack(np.meshgrid(pts, pts, pts), -1)  # (y,x,z)\n",
    "query_yxz = query_yxz.reshape(-1, 3)\n",
    "query_xyz = np.concatenate([query_yxz[:,1:2], query_yxz[:,0:1], query_yxz[:,2:3]],-1)\n",
    "#query_xyz[:,-1] *= -1\n",
    "\n",
    "bs_pts = query_xyz.shape[0]\n",
    "points = query_xyz[:,None]\n",
    "\n",
    "for tidx in range(0,render_len):\n",
    "    tidxf = int(tidx/render_len*frame_len)\n",
    "    print(tidxf)\n",
    "    metadata={}\n",
    "    metadata['appearance'] = tidxf* np.ones((points.shape[0],1)).astype(int)\n",
    "    metadata['warp'] = tidxf*np.ones((points.shape[0],1)).astype(int)\n",
    "    rays_dict={'query_xyz': query_xyz, 'metadata': metadata}\n",
    "\n",
    "    vol_o = extract_mesh(bs_pts, chunk, rays_dict, device_count, key_0, key_1, state)\n",
    "\n",
    "    print('fraction occupied:', (vol_o > threshold).astype(float).mean())\n",
    "    vertices, triangles = mcubes.marching_cubes(vol_o, threshold)\n",
    "    vertices = (vertices - grid_size/2)/grid_size*2\n",
    "    vertices = vertices * bound\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices, triangles)\n",
    "    camtxt = np.zeros((4,4))\n",
    "    camtxt[:3,:3] = test_cameras[tidxf].orientation\n",
    "    camtxt[:3,3] = camtxt[:3,:3].dot(-test_cameras[tidxf].position[:,None])[:,0]\n",
    "    camtxt[3,:2] = [test_cameras[tidxf].focal_length, \n",
    "                    test_cameras[tidxf].focal_length]\n",
    "    camtxt[3,2:] = test_cameras[tidxf].principal_point\n",
    "    \n",
    "\n",
    "    mesh.export('%s/%s-mesh-%05d.obj'%(target_dir,outseqname,tidx))\n",
    "    np.savetxt('%s/%s-cam-%05d.txt'%(target_dir,outseqname,tidx), camtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Nerfies Render Video.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
